{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5cb2abb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##nodejs:  https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/setting-up-node-on-ec2-instance.html\n",
    "\n",
    "# !pip install \"jupyterlab>=3\" \"ipywidgets>=7.6\" --user\n",
    "# !pip install jupyter-dash --user\n",
    "# !jupyter lab build --user\n",
    "\n",
    "# !pip install snowflake --user\n",
    "# !pip install snowflake-connector-python --user\n",
    "import os\n",
    "import sys\n",
    "path=!pwd\n",
    "sys.path.append(os.path.join(path[0], '..'))\n",
    "from utils import *\n",
    "import snowflake.connector\n",
    "\n",
    "class SnowflakeConnector(BaseConnector):\n",
    "    def __init__(self, credentials: Credentials):\n",
    "        keys = credentials.get_keys()\n",
    "        self._secrets = json.loads(keys.get('SecretString', \"{}\"))\n",
    "\n",
    "    def connect(self, dbname: str, schema: str = 'DEFAULT'):\n",
    "        ctx = snowflake.connector.connect(\n",
    "            user=self._secrets['login_name'],\n",
    "            password=self._secrets['login_password'],\n",
    "            account=self._secrets['account'],\n",
    "            warehouse=self._secrets['warehouse'],\n",
    "            database=dbname,\n",
    "            schema=schema\n",
    "        )\n",
    "\n",
    "        return ctx\n",
    "\n",
    "def run_query(querystr, ctx):\n",
    "    cursor_list = ctx.execute_string(\n",
    "        querystr\n",
    "        )\n",
    "    df = pd.DataFrame.from_records(cursor_list[-1].fetchall(), columns=[x[0] for x in cursor_list[-1].description])\n",
    "    df.columns= df.columns.str.lower()\n",
    "    \n",
    "    return df\n",
    "## Credentials\n",
    "SF_CREDS = 'datascience-max-dev-sagemaker-notebooks'\n",
    "\n",
    "## Snowflake connection \n",
    "conn=SnowflakeConnector(SSMPSCredentials(SF_CREDS))\n",
    "ctx=conn.connect(\"MAX_PROD\",\"DATASCIENCE_STAGE\")\n",
    "cur = ctx.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97afbece",
   "metadata": {},
   "source": [
    "## Query for extrapolated prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c2d870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20210801 saved\n",
      "20210901 saved\n"
     ]
    }
   ],
   "source": [
    "for val_date in ['20210801', '20210901']:\n",
    "    val_date_file = datetime.strptime(val_date, '%Y%m%d').strftime('%Y-%m-%d')\n",
    "\n",
    "    ### Base assets \n",
    "    querystr_base_assets = '''\n",
    "    --Step 4: Gather past metrics and create the basic heuristic forecast, plus median metrics tables\n",
    "    create or replace table max_dev.workspace.psi_past_base_assets_temp as \n",
    "    (select distinct\n",
    "          a.title_id\n",
    "        , coalesce(a.season_number,0) as season_number\n",
    "        , a.viewable_id\n",
    "        , title_name\n",
    "        , first_offered_date::date as asset_max_premiere\n",
    "        , end_utc_max::date as asset_max_end_dt\n",
    "        , coalesce(raod.season_first_offered_date::date,raod.title_first_offered_date::date) as season_premiere\n",
    "        , asset_run_time\n",
    "        , a.content_category\n",
    "        , episode_number_in_season\n",
    "        , content_source\n",
    "        , program_type\n",
    "        , category\n",
    "        , tier\n",
    "        , viewership_start_date as effective_start_date\n",
    "        , viewership_end_date as effective_end_date\n",
    "    from max_prod.catalog.reporting_asset_dim a\n",
    "    join max_prod.catalog.reporting_asset_offering_dim raod\n",
    "        on a.viewable_id = raod.viewable_id\n",
    "        and brand = 'HBO MAX'\n",
    "        and territory = 'HBO MAX DOMESTIC'\n",
    "        and channel = 'HBO MAX SUBSCRIPTION'\n",
    "    inner join max_prod.content_analytics.psi_past_title_metadata b\n",
    "        on a.title_id = b.viewership_title_id\n",
    "        and coalesce(a.season_number,0) = coalesce(b.viewership_season_number,0)\n",
    "    where 1 = 1\n",
    "    and asset_type IN ('FEATURE','ELEMENT')\n",
    "    and start_utc_max is not null\n",
    "    and a.content_category in ('movies','series','special')\n",
    "    and coalesce(raod.season_first_offered_date,raod.title_first_offered_date)  >= '2020-05-27 07:01:00.000'\n",
    "    order by season_premiere, title_name \n",
    "    );\n",
    "    select * from max_dev.workspace.psi_past_base_assets_temp;\n",
    "    '''\n",
    "\n",
    "\n",
    "    ### Train fv \n",
    "    querystr_train_fv=''' \n",
    "    set val_date = date({val_date}, 'YYYYMMDD');\n",
    "    --Step 4: Gather past metrics and create the basic heuristic forecast, plus median metrics tables\n",
    "    create or replace table max_dev.workspace.psi_past_base_temp as (\n",
    "    with fv as (\n",
    "        select\n",
    "              b.title_id\n",
    "            , b.title_name\n",
    "            , b.season_number\n",
    "            , b.content_category\n",
    "            , b.category\n",
    "            , tier\n",
    "            , request_time_gmt::date as request_date\n",
    "            , count(distinct concat(hbo_uuid, subscription_id)) as first_views\n",
    "        from MAX_PROD.BI_ANALYTICS.SUBSCRIPTION_FIRST_CONTENT_WATCHED a\n",
    "        inner join max_dev.workspace.psi_past_base_assets_temp b\n",
    "            on a.viewable_id = b.viewable_id\n",
    "            --and request_time_gmt::date between season_premiere_date and dateadd('day',90,season_premiere_date)\n",
    "            --and season_premiere_date >= '2020-05-27 07:00:01'\n",
    "        where 1 = 1\n",
    "            and request_time_gmt::date between asset_max_premiere and asset_max_end_dt\n",
    "            and request_time_gmt::date between effective_start_date and effective_end_date\n",
    "            and request_time_gmt::date < dateadd('days',-1,$val_date)\n",
    "            and country_iso_code in ('US','PR','GU')\n",
    "        group by 1,2,3,4,5,6,7\n",
    "        --order by 2,4\n",
    "    )\n",
    "    , dates as (\n",
    "        select distinct\n",
    "              rs.title_id\n",
    "            , rs.title_name\n",
    "            , rs.season_number\n",
    "            , rs.content_category\n",
    "            , rs.content_source\n",
    "            , rs.program_type\n",
    "            , rs.category\n",
    "            , rs.tier\n",
    "            --, rs.season_premiere\n",
    "            , rs.effective_start_date\n",
    "            , request_date\n",
    "            , case when request_date::date = effective_start_date::date then 1 else 0 end as premiere_ind\n",
    "            , count(distinct case when request_date::date = asset_max_premiere::date then viewable_id else null end) as asset_premiere_count\n",
    "            , round(sum(distinct case when request_date::date = asset_max_premiere::date then asset_run_time else 0 end)/3600,3) as premiering_hours_runtime\n",
    "        from max_dev.workspace.psi_past_base_assets_temp rs\n",
    "        cross join (\n",
    "            select distinct seq_date as request_date \n",
    "            from max_prod.staging.date_range \n",
    "            where seq_date < '2024-12-31'::date\n",
    "        ) rd\n",
    "        where rd.request_date between \n",
    "        coalesce(rs.effective_start_date,rs.season_premiere,rs.asset_max_premiere) \n",
    "        and dateadd('days',90,coalesce(rs.effective_start_date,rs.season_premiere,rs.asset_max_premiere))\n",
    "          and rd.request_date between effective_start_date and effective_end_date\n",
    "        group by 1,2,3,4,5,6,7,8,9,10,11\n",
    "        order by 2,3,8\n",
    "    )\n",
    "        select dt.*\n",
    "            , coalesce(first_views,0) as first_views\n",
    "            , dt.request_date - effective_start_date as days_since_premiere\n",
    "            , $val_date - effective_start_date -1 as days_on_platform\n",
    "            , case when $val_date - effective_start_date - 1 >=\n",
    "                case when dt.category = 'Popcorn' and year(effective_start_date) < 2022 then 31 else 90 end\n",
    "            then 1 else 0 end as finished_window_flag\n",
    "        from dates dt\n",
    "        left join fv\n",
    "            on dt.title_id = fv.title_id\n",
    "            and dt.season_number = fv.season_number\n",
    "            and dt.request_date = fv.request_date\n",
    "            and dt.content_category = fv.content_category\n",
    "            and dt.category = fv.category\n",
    "            and dt.tier = fv.tier\n",
    "        where 1 = 1\n",
    "        --and dt.title_name like 'In Treatment'\n",
    "        order by title_id, title_name, season_number, category, request_date\n",
    "    );\n",
    "    select \n",
    "    * \n",
    "    from max_dev.workspace.psi_past_base_temp;\n",
    "    '''.format(val_date = val_date)\n",
    "\n",
    "    \n",
    "    querystr_psi_median_decay='''\n",
    "    set val_date = date({val_date}, 'YYYYMMDD');\n",
    "    create or replace table max_dev.workspace.psi_median_decay as (\n",
    "    with title_totals as (\n",
    "        select\n",
    "              title_id\n",
    "            , title_name\n",
    "            , season_number\n",
    "            , content_category\n",
    "            , category\n",
    "            , tier\n",
    "            , finished_window_flag\n",
    "            , sum(first_views) as total_first_views\n",
    "        from max_dev.workspace.psi_past_base_temp\n",
    "        --where finished_window_flag = 1\n",
    "        group by 1,2,3,4,5,6,7\n",
    "        )\n",
    "    , enriched_base as (\n",
    "        select\n",
    "            base.*\n",
    "            , div0(first_views,total_first_views) as first_views_pct\n",
    "        from max_dev.workspace.psi_past_base_temp base\n",
    "        left join title_totals tt\n",
    "        on base.title_id = tt.title_id\n",
    "        and base.season_number = tt.season_number\n",
    "        and base.content_category = tt.content_category\n",
    "        and base.category = tt.category\n",
    "        and base.tier = tt.tier\n",
    "        and tt.finished_window_flag = 1\n",
    "        where 1 = 1\n",
    "        and total_first_views >= 0\n",
    "        or base.finished_window_flag = 0\n",
    "        )\n",
    "    , median_decay_pre as (\n",
    "        select\n",
    "              category\n",
    "            , days_since_premiere\n",
    "            , median(first_views_pct) as med_first_views_pct\n",
    "        from enriched_base\n",
    "        where finished_window_flag = 1\n",
    "        group by 1,2\n",
    "        order by 1,2\n",
    "        )\n",
    "    , median_decay_modifier as (\n",
    "        select\n",
    "              category\n",
    "            , sum(med_first_views_pct) as med_fv_mod\n",
    "        from median_decay_pre\n",
    "        group by 1\n",
    "        )\n",
    "    select\n",
    "          a.category\n",
    "        , days_since_premiere\n",
    "        , med_first_views_pct/med_fv_mod as med_first_views_pct\n",
    "    from median_decay_pre a\n",
    "    join median_decay_modifier b\n",
    "    on a.category = b.category\n",
    "    );\n",
    "    select \n",
    "    * \n",
    "    from max_dev.workspace.psi_median_decay;\n",
    "    '''.format(val_date = val_date)\n",
    "\n",
    "    \n",
    "    querystr_psi_daily_viewership='''\n",
    "    set val_date = date({val_date}, 'YYYYMMDD');\n",
    "    create or replace table max_dev.workspace.psi_past_current_daily_viewership as (\n",
    "    with current_running_assets as (\n",
    "    select\n",
    "          title_id\n",
    "        , title_name\n",
    "        , season_number\n",
    "        , content_category\n",
    "        , category\n",
    "        , tier\n",
    "        , effective_start_date\n",
    "        , max(days_since_premiere) days_so_far\n",
    "        , sum(first_views) as fv_so_far\n",
    "    from max_dev.workspace.psi_past_base_temp\n",
    "    where 1 = 1\n",
    "    and request_date < dateadd('days',-1,$val_date)\n",
    "    and effective_start_date < dateadd('days',-4,$val_date)\n",
    "    and finished_window_flag = 0\n",
    "    group by 1,2,3,4,5,6,7\n",
    "    )\n",
    "    , current_running_assets_enriched as (\n",
    "    select\n",
    "          title_id\n",
    "        , title_name\n",
    "        , season_number\n",
    "        , content_category\n",
    "        , a.category\n",
    "        , a.tier\n",
    "        , effective_start_date\n",
    "        , days_so_far\n",
    "        , fv_so_far\n",
    "        , sum(med_first_views_pct) fv_pct_so_far\n",
    "    from current_running_assets a\n",
    "    join max_dev.workspace.psi_median_decay b\n",
    "    on case when a.category = 'Popcorn' and year(effective_start_date) >= 2022 then 'Scripted Features'\n",
    "        else a. category end = b.category\n",
    "    and days_since_premiere <= days_so_far\n",
    "    group by 1,2,3,4,5,6,7,8,9\n",
    "    )\n",
    "    , current_running_assets_predicted_totals as (\n",
    "    select\n",
    "          title_id\n",
    "        , title_name\n",
    "        , season_number\n",
    "        , content_category\n",
    "        , category\n",
    "        , tier\n",
    "        , effective_start_date\n",
    "        , fv_so_far/fv_pct_so_far as predicted_total_first_views\n",
    "    from current_running_assets_enriched\n",
    "    )\n",
    "    select\n",
    "          a.*\n",
    "        , case when request_date < dateadd('days',-1, $val_date) then first_views\n",
    "        else round(b.med_first_views_pct * c.predicted_total_first_views,0) end as predicted_first_views\n",
    "    from max_dev.workspace.psi_past_base_temp a\n",
    "    left join max_dev.workspace.psi_median_decay b\n",
    "    on case when a.category = 'Popcorn' and year(effective_start_date) >= 2022 then 'Scripted Features'\n",
    "        else a. category end = b.category\n",
    "    and a.days_since_premiere = b.days_since_premiere\n",
    "    left join current_running_assets_predicted_totals c\n",
    "    on a.title_id = c.title_id\n",
    "    and a.season_number = c.season_number\n",
    "    and a.content_category = c.content_category\n",
    "    and a.category = c.category\n",
    "    and a.tier =  c.tier\n",
    "    --where a.title_name like '%Snyder%'\n",
    "    );\n",
    "    select \n",
    "    *,\n",
    "    'past' as schedule_label\n",
    "    from max_dev.workspace.psi_past_current_daily_viewership\n",
    "    where 1 = 1\n",
    "    and effective_start_date < dateadd('days',-4,$val_date::date);\n",
    "    '''.format(val_date = val_date)\n",
    "\n",
    "    \n",
    "    df = run_query(querystr_base_assets, ctx)\n",
    "    df_train_fv = run_query(querystr_train_fv, ctx)\n",
    "    df_train_fv.to_csv('s3://hbo-ingest-datascience-content-dev/psi_first_views/dev/fv_train_{}.csv'.format(val_date_file))\n",
    "\n",
    "    df_median_decay= run_query(querystr_psi_median_decay, ctx)\n",
    "    df_fv_ext= run_query(querystr_psi_daily_viewership, ctx)\n",
    "    df_fv_ext.to_csv('s3://hbo-ingest-datascience-content-dev/psi_first_views/dev/fv_ext_{}.csv'.format(val_date_file))\n",
    "     \n",
    "    print(f'{val_date} saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae80b9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_date_file='2022-02-11'\n",
    "querystr='''\n",
    "select \n",
    "* \n",
    "from max_prod.content_analytics.psi_daily_rw_mean_forecast \n",
    "where finished_window_flag=0 and days_on_platform>0  \n",
    "'''\n",
    "\n",
    "df_rwm= run_query(querystr, ctx)\n",
    "df_rwm.to_csv('s3://hbo-ingest-datascience-content-dev/psi_first_views/dev/rwm_{}.csv'.format(val_date_file))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
