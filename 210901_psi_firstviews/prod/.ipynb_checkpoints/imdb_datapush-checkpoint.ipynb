{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b7e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##nodejs:  https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/setting-up-node-on-ec2-instance.html\n",
    "\n",
    "# !pip install \"jupyterlab>=3\" \"ipywidgets>=7.6\"\n",
    "# !pip install jupyter-dash\n",
    "# !jupyter lab build\n",
    "\n",
    "\n",
    "# !pip install snowflake --user\n",
    "# !pip install snowflake-connector-python --user\n",
    "# !pip install category_encoders\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm --user\n",
    "import os\n",
    "import sys\n",
    "path=!pwd\n",
    "# sys.path.append(os.path.join(path[0], '..'))\n",
    "# sys.path.append('/home/ec2-user/SageMaker/jupyter-notebooks/')\n",
    "# from utils import *\n",
    "import snowflake.connector\n",
    "from datetime import timedelta\n",
    "\n",
    "from category_encoders import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import r2_score as r2_score\n",
    "import sklearn.model_selection\n",
    "\n",
    "class Credentials(metaclass=ABCMeta):\n",
    "    pass\n",
    "    \n",
    "    \n",
    "class SSMPSCredentials(Credentials):\n",
    "    def __init__(self, secretid: str):\n",
    "        self._secretid = secretid\n",
    "        self._secrets = {}\n",
    "        \n",
    "    def get_keys(self):\n",
    "        \"\"\"\n",
    "        credential fetching \n",
    "        \"\"\"\n",
    "        _aws_sm_args = {'service_name': 'secretsmanager', 'region_name': 'us-east-1'}\n",
    "        secrets_client = boto3.client(**_aws_sm_args)\n",
    "        get_secret_value_response = secrets_client.get_secret_value(SecretId=self._secretid)\n",
    "        return get_secret_value_response\n",
    "    \n",
    "    \n",
    "class BaseConnector(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def connect(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class SnowflakeConnector(BaseConnector):\n",
    "    def __init__(self, credentials: Credentials):\n",
    "        keys = credentials.get_keys()\n",
    "        self._secrets = json.loads(keys.get('SecretString', \"{}\"))\n",
    "\n",
    "    def connect(self, dbname: str, schema: str = 'DEFAULT'):\n",
    "        ctx = snowflake.connector.connect(\n",
    "            user=self._secrets['login_name'],\n",
    "            password=self._secrets['login_password'],\n",
    "            account=self._secrets['account'],\n",
    "            warehouse=self._secrets['warehouse'],\n",
    "            database=dbname,\n",
    "            schema=schema\n",
    "        )\n",
    "\n",
    "        return ctx\n",
    "\n",
    "\n",
    "def run_query(query, dbname, schema):\n",
    "    SF_CREDS = 'datascience-max-dev-sagemaker-notebooks'\n",
    "\n",
    "    conn=SnowflakeConnector(SSMPSCredentials(SF_CREDS))\n",
    "    ctx=conn.connect(dbname,schema)\n",
    "    cursor = ctx.cursor()\n",
    "    cursor.execute(query)\n",
    "    df = pd.DataFrame(cursor.fetchall(), columns = [desc[0] for desc in cursor.description])\n",
    "    df.columns= df.columns.str.lower()\n",
    "    return df    \n",
    "## Credentials\n",
    "SF_CREDS = 'datascience-max-dev-sagemaker-notebooks'\n",
    "\n",
    "## Snowflake connection \n",
    "conn=SnowflakeConnector(SSMPSCredentials(SF_CREDS))\n",
    "ctx=conn.connect(\"MAX_PROD\",\"DATASCIENCE_STAGE\")\n",
    "cur = ctx.cursor()\n",
    "\n",
    "def cvdf_to_snowflake(df, table_name):\n",
    "    stage = '@HBO_OUTBOUND_DATASCIENCE_CONTENT_DEV'\n",
    "    output_bucket = \"hbo-outbound-datascience-content-dev\"\n",
    "    filename ='psi/' + table_name + '.csv'\n",
    "    dbname, schema = 'MAX_DEV', 'WORKSPACE'\n",
    "    \n",
    "    csv_buffer = io.StringIO()\n",
    "    df.to_csv(csv_buffer, index = False)\n",
    "    content = csv_buffer.getvalue()\n",
    "    client = boto3.client('s3')\n",
    "    client.put_object(Bucket=output_bucket, Key=filename, Body=content)\n",
    "\n",
    "    print ('Create Table: ' + table_name)\n",
    "    run_query('''\n",
    "    create or replace table {table_name}(\n",
    "    title_name varchar,\n",
    "    tier int,\n",
    "    season_number int, \n",
    "    category varchar,\n",
    "    effective_start_date varchar,\n",
    "    imdb_title_name varchar,\n",
    "    imdb_title_id varchar,\n",
    "    content_category varchar\n",
    "    )\n",
    "    '''.format(table_name = table_name), dbname, schema)\n",
    "\n",
    "    print ('Begin Uploading')\n",
    "    run_query('''\n",
    "    insert into max_dev.workspace.{table_name}\n",
    "\n",
    "    select \n",
    "          $1, $2, $3, $4, $5, $6, $7, $8\n",
    "    from {stage}/psi/{file_name}\n",
    "\n",
    "     (FILE_FORMAT => csv_v2)\n",
    "\n",
    "    '''.format(stage = stage, table_name = table_name,\n",
    "              file_name = table_name+'.csv')\n",
    "            , dbname, schema)\n",
    "\n",
    "    print ('Finish Uploading')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a781fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Table: future_title_imdb_map\n",
      "Begin Uploading\n",
      "Finish Uploading\n"
     ]
    }
   ],
   "source": [
    "## Upload manually entered data to snowflake \n",
    "import io\n",
    "\n",
    "df_fp = pd.read_csv('s3://hbo-ingest-datascience-content-dev/psi_firstviews/future_program_imdb_id_full.csv')\n",
    "df_fp = df_fp.rename(columns={'premiere_date':'effective_start_date',\n",
    "                             'title_name_imdb':'imdb_title_name',\n",
    "                             'imdb_id':'imdb_title_id',\n",
    "                             'program_type':'content_category'})\n",
    "df_fp.loc[df_fp.content_category=='movie','content_category'] = 'movies'\n",
    "df_fp['title_id'] = 0\n",
    "df_fp['first_views'] = 0\n",
    "\n",
    "df_fp.to_csv('s3://hbo-ingest-datascience-content-dev/psi_firstviews/future_program_imdb_id_full.csv')\n",
    "df_fp = df_fp[['title_name', 'tier', 'season_number', 'category',\n",
    "       'effective_start_date', 'imdb_title_name','imdb_title_id', 'content_category']]\n",
    "\n",
    "cvdf_to_snowflake(df_fp, 'future_title_imdb_map')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
