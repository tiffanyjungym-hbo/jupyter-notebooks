{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6503da47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##nodejs:  https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/setting-up-node-on-ec2-instance.html\n",
    "\n",
    "# !pip install \"jupyterlab>=3\" \"ipywidgets>=7.6\" --user\n",
    "# !pip install jupyter-dash --user\n",
    "# !jupyter lab build --user\n",
    "\n",
    "# !pip install snowflake --user\n",
    "# !pip install snowflake-connector-python --user\n",
    "import os\n",
    "import sys\n",
    "path=!pwd\n",
    "sys.path.append(os.path.join(path[0], '..'))\n",
    "from utils import *\n",
    "import snowflake.connector\n",
    "\n",
    "class SnowflakeConnector(BaseConnector):\n",
    "    def __init__(self, credentials: Credentials):\n",
    "        keys = credentials.get_keys()\n",
    "        self._secrets = json.loads(keys.get('SecretString', \"{}\"))\n",
    "\n",
    "    def connect(self, dbname: str, schema: str = 'DEFAULT'):\n",
    "        ctx = snowflake.connector.connect(\n",
    "            user=self._secrets['login_name'],\n",
    "            password=self._secrets['login_password'],\n",
    "            account=self._secrets['account'],\n",
    "            warehouse=self._secrets['warehouse'],\n",
    "            database=dbname,\n",
    "            schema=schema\n",
    "        )\n",
    "\n",
    "        return ctx\n",
    "    \n",
    "## Credentials\n",
    "SF_CREDS = 'datascience-max-dev-sagemaker-notebooks'\n",
    "\n",
    "## Snowflake connection \n",
    "conn=SnowflakeConnector(SSMPSCredentials(SF_CREDS))\n",
    "ctx=conn.connect(\"MAX_PROD\",\"DATASCIENCE_STAGE\")\n",
    "cur = ctx.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3251a21",
   "metadata": {},
   "source": [
    "## Get Actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c223fa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_id</th>\n",
       "      <th>title_name</th>\n",
       "      <th>season_number</th>\n",
       "      <th>content_category</th>\n",
       "      <th>content_source</th>\n",
       "      <th>program_type</th>\n",
       "      <th>category</th>\n",
       "      <th>tier</th>\n",
       "      <th>effective_start_date</th>\n",
       "      <th>request_date</th>\n",
       "      <th>premiere_ind</th>\n",
       "      <th>asset_premiere_count</th>\n",
       "      <th>premiering_hours_runtime</th>\n",
       "      <th>first_views</th>\n",
       "      <th>hours_viewed</th>\n",
       "      <th>days_since_premiere</th>\n",
       "      <th>days_on_platform</th>\n",
       "      <th>finished_window_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GXvNE_wCRNYaEUwEAAAGh</td>\n",
       "      <td>Showbiz Kids</td>\n",
       "      <td>0</td>\n",
       "      <td>movies</td>\n",
       "      <td>HBO</td>\n",
       "      <td>original</td>\n",
       "      <td>Documentary Features</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>346</td>\n",
       "      <td>11597.721</td>\n",
       "      <td>4</td>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GXvNE_wCRNYaEUwEAAAGh</td>\n",
       "      <td>Showbiz Kids</td>\n",
       "      <td>0</td>\n",
       "      <td>movies</td>\n",
       "      <td>HBO</td>\n",
       "      <td>original</td>\n",
       "      <td>Documentary Features</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>115</td>\n",
       "      <td>4434.831</td>\n",
       "      <td>5</td>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GXvNE_wCRNYaEUwEAAAGh</td>\n",
       "      <td>Showbiz Kids</td>\n",
       "      <td>0</td>\n",
       "      <td>movies</td>\n",
       "      <td>HBO</td>\n",
       "      <td>original</td>\n",
       "      <td>Documentary Features</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>130</td>\n",
       "      <td>3707.616</td>\n",
       "      <td>6</td>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GXvNE_wCRNYaEUwEAAAGh</td>\n",
       "      <td>Showbiz Kids</td>\n",
       "      <td>0</td>\n",
       "      <td>movies</td>\n",
       "      <td>HBO</td>\n",
       "      <td>original</td>\n",
       "      <td>Documentary Features</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>124</td>\n",
       "      <td>3571.709</td>\n",
       "      <td>7</td>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GXvNE_wCRNYaEUwEAAAGh</td>\n",
       "      <td>Showbiz Kids</td>\n",
       "      <td>0</td>\n",
       "      <td>movies</td>\n",
       "      <td>HBO</td>\n",
       "      <td>original</td>\n",
       "      <td>Documentary Features</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>92</td>\n",
       "      <td>2781.734</td>\n",
       "      <td>8</td>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                title_id    title_name  season_number content_category  \\\n",
       "0  GXvNE_wCRNYaEUwEAAAGh  Showbiz Kids              0           movies   \n",
       "1  GXvNE_wCRNYaEUwEAAAGh  Showbiz Kids              0           movies   \n",
       "2  GXvNE_wCRNYaEUwEAAAGh  Showbiz Kids              0           movies   \n",
       "3  GXvNE_wCRNYaEUwEAAAGh  Showbiz Kids              0           movies   \n",
       "4  GXvNE_wCRNYaEUwEAAAGh  Showbiz Kids              0           movies   \n",
       "\n",
       "  content_source program_type              category tier effective_start_date  \\\n",
       "0            HBO     original  Documentary Features    3           2020-07-15   \n",
       "1            HBO     original  Documentary Features    3           2020-07-15   \n",
       "2            HBO     original  Documentary Features    3           2020-07-15   \n",
       "3            HBO     original  Documentary Features    3           2020-07-15   \n",
       "4            HBO     original  Documentary Features    3           2020-07-15   \n",
       "\n",
       "  request_date  premiere_ind  asset_premiere_count premiering_hours_runtime  \\\n",
       "0   2020-07-19             0                     0                    0.000   \n",
       "1   2020-07-20             0                     0                    0.000   \n",
       "2   2020-07-21             0                     0                    0.000   \n",
       "3   2020-07-22             0                     0                    0.000   \n",
       "4   2020-07-23             0                     0                    0.000   \n",
       "\n",
       "   first_views hours_viewed  days_since_premiere  days_on_platform  \\\n",
       "0          346    11597.721                    4               484   \n",
       "1          115     4434.831                    5               484   \n",
       "2          130     3707.616                    6               484   \n",
       "3          124     3571.709                    7               484   \n",
       "4           92     2781.734                    8               484   \n",
       "\n",
       "   finished_window_flag  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "querystr = '''\n",
    "set val_date = to_date(convert_timezone('America/Los_Angeles','2021-11-13'));\n",
    "--Step 4: Gather past metrics and create the basic heuristic forecast, plus median metrics tables\n",
    "create or replace table max_dev.workspace.psi_past_base_full as (\n",
    "with assets as (\n",
    "select distinct\n",
    "      a.title_id\n",
    "    , coalesce(a.season_number,0) as season_number\n",
    "    , a.viewable_id\n",
    "    , title_name\n",
    "    , first_offered_date::date as asset_max_premiere\n",
    "    , end_utc_max::date as asset_max_end_dt\n",
    "    , coalesce(raod.season_first_offered_date::date,raod.title_first_offered_date::date) as season_premiere\n",
    "    , asset_run_time\n",
    "    , a.content_category\n",
    "    , episode_number_in_season\n",
    "    , content_source\n",
    "    , program_type\n",
    "    , category\n",
    "    , tier\n",
    "    , viewership_start_date as effective_start_date\n",
    "    , viewership_end_date as effective_end_date\n",
    "from max_prod.catalog.reporting_asset_dim a\n",
    "join max_prod.catalog.reporting_asset_offering_dim raod\n",
    "on a.viewable_id = raod.viewable_id\n",
    "and brand = 'HBO MAX'\n",
    "and territory = 'HBO MAX DOMESTIC'\n",
    "and channel = 'HBO MAX SUBSCRIPTION'\n",
    "inner join max_prod.content_analytics.psi_past_title_metadata b\n",
    "on a.title_id = b.viewership_title_id\n",
    "and coalesce(a.season_number,0) = coalesce(b.viewership_season_number,0)\n",
    "where 1 = 1\n",
    "and asset_type IN ('FEATURE','ELEMENT')\n",
    "and start_utc_max is not null\n",
    "and a.content_category in ('movies','series','special')\n",
    "and coalesce(raod.season_first_offered_date,raod.title_first_offered_date)  >= '2020-05-27 07:01:00.000'\n",
    "order by season_premiere, title_name-- desc\n",
    ")\n",
    ", fv as (\n",
    "    select\n",
    "          b.title_id\n",
    "        , b.title_name\n",
    "        , b.season_number\n",
    "        , b.content_category\n",
    "        , b.category\n",
    "        , tier\n",
    "        , request_time_gmt::date as request_date\n",
    "        , count(distinct concat(hbo_uuid, subscription_id)) as first_views\n",
    "    from MAX_PROD.BI_ANALYTICS.SUBSCRIPTION_FIRST_CONTENT_WATCHED a\n",
    "    inner join assets b\n",
    "        on a.viewable_id = b.viewable_id\n",
    "        --and request_time_gmt::date between season_premiere_date and dateadd('day',90,season_premiere_date)\n",
    "        --and season_premiere_date >= '2020-05-27 07:00:01'\n",
    "    where 1 = 1\n",
    "    and request_time_gmt::date between asset_max_premiere and asset_max_end_dt\n",
    "    and request_time_gmt::date between effective_start_date and effective_end_date\n",
    "    and request_time_gmt::date < dateadd('days',-1,$val_date)\n",
    "    and country_iso_code in ('US','PR','GU')\n",
    "    group by 1,2,3,4,5,6,7\n",
    "    --order by 2,4\n",
    ")\n",
    ", hv as (\n",
    "    select\n",
    "          b.title_id\n",
    "        , b.title_name\n",
    "        , b.season_number\n",
    "        , b.content_category\n",
    "        , b.category\n",
    "        , tier\n",
    "        , request_time_gmt::date as request_date\n",
    "        , coalesce(round(sum(stream_elapsed_play_seconds)/3600,3), 0) as hours_viewed\n",
    "    from max_prod.viewership.max_user_stream_heartbeat a\n",
    "    inner join assets b\n",
    "        on a.viewable_id = b.viewable_id\n",
    "    where 1 = 1\n",
    "    and stream_elapsed_play_seconds >= 120\n",
    "    and request_time_gmt > '2020-05-27 07:00:00'\n",
    "    and request_time_gmt::date between asset_max_premiere and asset_max_end_dt\n",
    "    and request_time_gmt::date between effective_start_date and effective_end_date\n",
    "    and request_time_gmt::date < dateadd('days',-1,$val_date)\n",
    "    group by 1,2,3,4,5,6,7\n",
    ")\n",
    ", dates as (\n",
    "    select distinct\n",
    "          rs.title_id\n",
    "        , rs.title_name\n",
    "        , rs.season_number\n",
    "        , rs.content_category\n",
    "        , rs.content_source\n",
    "        , rs.program_type\n",
    "        , rs.category\n",
    "        , rs.tier\n",
    "        --, rs.season_premiere\n",
    "        , rs.effective_start_date\n",
    "        , request_date\n",
    "        , case when request_date::date = effective_start_date::date then 1 else 0 end as premiere_ind\n",
    "        , count(distinct case when request_date::date = asset_max_premiere::date then viewable_id else null end) as asset_premiere_count\n",
    "        , round(sum(distinct case when request_date::date = asset_max_premiere::date then asset_run_time else 0 end)/3600,3) as premiering_hours_runtime\n",
    "    from assets rs\n",
    "    cross join (\n",
    "        select distinct seq_date as request_date \n",
    "        from max_prod.staging.date_range \n",
    "        where seq_date < '2024-12-31'::date\n",
    "    ) rd\n",
    "    where rd.request_date between \n",
    "    coalesce(rs.effective_start_date,rs.season_premiere,rs.asset_max_premiere) \n",
    "    and dateadd('days',90,coalesce(rs.effective_start_date,rs.season_premiere,rs.asset_max_premiere))\n",
    "      and rd.request_date between effective_start_date and effective_end_date\n",
    "    group by 1,2,3,4,5,6,7,8,9,10,11\n",
    "    order by 2,3,8\n",
    ")\n",
    "    select dt.*\n",
    "        , coalesce(first_views,0) as first_views\n",
    "        , coalesce(hours_viewed,0) as hours_viewed\n",
    "        , dt.request_date - effective_start_date as days_since_premiere\n",
    "        , $val_date - effective_start_date -1 as days_on_platform\n",
    "        , case when $val_date - effective_start_date - 1 >=\n",
    "            case when dt.category = 'Popcorn' and year(effective_start_date) < 2022 then 31 else 90 end\n",
    "        then 1 else 0 end as finished_window_flag\n",
    "    from dates dt\n",
    "    left join hv\n",
    "    on dt.title_id = hv.title_id\n",
    "    and dt.season_number = hv.season_number\n",
    "    and dt.request_date = hv.request_date\n",
    "    and dt.content_category = hv.content_category\n",
    "    and dt.category = hv.category\n",
    "    and dt.tier = hv.tier\n",
    "    left join fv\n",
    "    on dt.title_id = fv.title_id\n",
    "    and dt.season_number = fv.season_number\n",
    "    and dt.request_date = fv.request_date\n",
    "    and dt.content_category = fv.content_category\n",
    "    and dt.category = fv.category\n",
    "    and dt.tier = fv.tier\n",
    "    where 1 = 1\n",
    "    --and dt.title_name like 'In Treatment'\n",
    "    order by title_id, title_name, season_number, category, request_date\n",
    ");\n",
    "select\n",
    "* \n",
    "from max_dev.workspace.psi_past_base_full\n",
    "'''\n",
    "\n",
    "cursor_list = ctx.execute_string(\n",
    "    querystr\n",
    "    )\n",
    "df = pd.DataFrame.from_records(cursor_list[-1].fetchall(), columns=[x[0] for x in cursor_list[-1].description])\n",
    "df.columns= df.columns.str.lower()\n",
    "display(df.head())\n",
    "df.to_csv('s3://datascience-hbo-users/users/tjung/psi/fv_actual_1113.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1afe03",
   "metadata": {},
   "source": [
    "## Full query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099434b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  title_id                   title_name  season_number content_category  \\\n",
      "0     None  HBO 2024 TBD Doc Feature 14              0             None   \n",
      "1     None  HBO 2024 TBD Doc Feature 15              0             None   \n",
      "2     None  HBO 2024 TBD Doc Feature 16              0             None   \n",
      "3     None  HBO 2024 TBD Doc Feature 12              0             None   \n",
      "4     None  HBO 2024 TBD Doc Feature 13              0             None   \n",
      "\n",
      "  content_source program_type              category tier premiere_date  \\\n",
      "0           None         None  Documentary Features    3    2024-06-15   \n",
      "1           None         None  Documentary Features    3    2024-06-15   \n",
      "2           None         None  Documentary Features    3    2024-06-15   \n",
      "3           None         None  Documentary Features    3    2024-05-15   \n",
      "4           None         None  Documentary Features    2    2024-05-23   \n",
      "\n",
      "     seq_date  num_premiering_titles  num_episodes_released  \\\n",
      "0  2024-07-24                      0                      0   \n",
      "1  2024-07-24                      0                      0   \n",
      "2  2024-07-24                      0                      0   \n",
      "3  2024-07-24                      0                      0   \n",
      "4  2024-07-24                      0                      0   \n",
      "\n",
      "   num_hours_released  first_views  hours_viewed  says_since_premiere  \\\n",
      "0                 0.0            0             0                   39   \n",
      "1                 0.0            0             0                   39   \n",
      "2                 0.0            0             0                   39   \n",
      "3                 0.0            0             0                   70   \n",
      "4                 0.0            0             0                   62   \n",
      "\n",
      "   days_on_platform  finished_window_flag  predicted_first_views  \\\n",
      "0             -1020                     0                   32.0   \n",
      "1             -1020                     0                   32.0   \n",
      "2             -1020                     0                   32.0   \n",
      "3              -989                     0                   10.0   \n",
      "4              -997                     0                  139.0   \n",
      "\n",
      "  predicted_hours_viewed schedule_label  \n",
      "0              2794.1636          alpha  \n",
      "1              2794.1636          alpha  \n",
      "2              2794.1636          alpha  \n",
      "3              1158.5477          alpha  \n",
      "4             13803.0376          alpha  \n"
     ]
    }
   ],
   "source": [
    "querystr='''\n",
    "-- s0\n",
    "set val_date = to_date(convert_timezone('America/Los_Angeles','2021-09-01'));\n",
    "--Step 4: Gather past metrics and create the basic heuristic forecast, plus median metrics tables\n",
    "create or replace table max_dev.workspace.psi_past_base_temp as (\n",
    "with assets as (\n",
    "select distinct\n",
    "      a.title_id\n",
    "    , coalesce(a.season_number,0) as season_number\n",
    "    , a.viewable_id\n",
    "    , title_name\n",
    "    , first_offered_date::date as asset_max_premiere\n",
    "    , end_utc_max::date as asset_max_end_dt\n",
    "    , coalesce(raod.season_first_offered_date::date,raod.title_first_offered_date::date) as season_premiere\n",
    "    , asset_run_time\n",
    "    , a.content_category\n",
    "    , episode_number_in_season\n",
    "    , content_source\n",
    "    , program_type\n",
    "    , category\n",
    "    , tier\n",
    "    , viewership_start_date as effective_start_date\n",
    "    , viewership_end_date as effective_end_date\n",
    "from max_prod.catalog.reporting_asset_dim a\n",
    "join max_prod.catalog.reporting_asset_offering_dim raod\n",
    "on a.viewable_id = raod.viewable_id\n",
    "and brand = 'HBO MAX'\n",
    "and territory = 'HBO MAX DOMESTIC'\n",
    "and channel = 'HBO MAX SUBSCRIPTION'\n",
    "inner join max_prod.content_analytics.psi_past_title_metadata b\n",
    "on a.title_id = b.viewership_title_id\n",
    "and coalesce(a.season_number,0) = coalesce(b.viewership_season_number,0)\n",
    "where 1 = 1\n",
    "and asset_type IN ('FEATURE','ELEMENT')\n",
    "and start_utc_max is not null\n",
    "and a.content_category in ('movies','series','special')\n",
    "and coalesce(raod.season_first_offered_date,raod.title_first_offered_date)  >= '2020-05-27 07:01:00.000'\n",
    "order by season_premiere, title_name-- desc\n",
    ")\n",
    ", fv as (\n",
    "    select\n",
    "          b.title_id\n",
    "        , b.title_name\n",
    "        , b.season_number\n",
    "        , b.content_category\n",
    "        , b.category\n",
    "        , tier\n",
    "        , request_time_gmt::date as request_date\n",
    "        , count(distinct concat(hbo_uuid, subscription_id)) as first_views\n",
    "    from MAX_PROD.BI_ANALYTICS.SUBSCRIPTION_FIRST_CONTENT_WATCHED a\n",
    "    inner join assets b\n",
    "        on a.viewable_id = b.viewable_id\n",
    "        --and request_time_gmt::date between season_premiere_date and dateadd('day',90,season_premiere_date)\n",
    "        --and season_premiere_date >= '2020-05-27 07:00:01'\n",
    "    where 1 = 1\n",
    "    and request_time_gmt::date between asset_max_premiere and asset_max_end_dt\n",
    "    and request_time_gmt::date between effective_start_date and effective_end_date\n",
    "    and request_time_gmt::date < dateadd('days',-1,$val_date)\n",
    "    and country_iso_code in ('US','PR','GU')\n",
    "    group by 1,2,3,4,5,6,7\n",
    "    --order by 2,4\n",
    ")\n",
    ", hv as (\n",
    "    select\n",
    "          b.title_id\n",
    "        , b.title_name\n",
    "        , b.season_number\n",
    "        , b.content_category\n",
    "        , b.category\n",
    "        , tier\n",
    "        , request_time_gmt::date as request_date\n",
    "        , coalesce(round(sum(stream_elapsed_play_seconds)/3600,3), 0) as hours_viewed\n",
    "    from max_prod.viewership.max_user_stream_heartbeat a\n",
    "    inner join assets b\n",
    "        on a.viewable_id = b.viewable_id\n",
    "    where 1 = 1\n",
    "    and stream_elapsed_play_seconds >= 120\n",
    "    and request_time_gmt > '2020-05-27 07:00:00'\n",
    "    and request_time_gmt::date between asset_max_premiere and asset_max_end_dt\n",
    "    and request_time_gmt::date between effective_start_date and effective_end_date\n",
    "    and request_time_gmt::date < dateadd('days',-1,$val_date)\n",
    "    group by 1,2,3,4,5,6,7\n",
    ")\n",
    ", dates as (\n",
    "    select distinct\n",
    "          rs.title_id\n",
    "        , rs.title_name\n",
    "        , rs.season_number\n",
    "        , rs.content_category\n",
    "        , rs.content_source\n",
    "        , rs.program_type\n",
    "        , rs.category\n",
    "        , rs.tier\n",
    "        --, rs.season_premiere\n",
    "        , rs.effective_start_date\n",
    "        , request_date\n",
    "        , case when request_date::date = effective_start_date::date then 1 else 0 end as premiere_ind\n",
    "        , count(distinct case when request_date::date = asset_max_premiere::date then viewable_id else null end) as asset_premiere_count\n",
    "        , round(sum(distinct case when request_date::date = asset_max_premiere::date then asset_run_time else 0 end)/3600,3) as premiering_hours_runtime\n",
    "    from assets rs\n",
    "    cross join (\n",
    "        select distinct seq_date as request_date from max_prod.staging.date_range where seq_date < '2024-12-31'::date\n",
    "    ) rd\n",
    "    where rd.request_date between coalesce(rs.effective_start_date,rs.season_premiere,rs.asset_max_premiere) and dateadd('days',90,coalesce(rs.effective_start_date,rs.season_premiere,rs.asset_max_premiere))\n",
    "      and rd.request_date between effective_start_date and effective_end_date\n",
    "    group by 1,2,3,4,5,6,7,8,9,10,11\n",
    "    order by 2,3,8\n",
    ")\n",
    "    select dt.*\n",
    "        , coalesce(first_views,0) as first_views\n",
    "        , coalesce(hours_viewed,0) as hours_viewed\n",
    "        , dt.request_date - effective_start_date as days_since_premiere\n",
    "        , $val_date - effective_start_date -1 as days_on_platform\n",
    "        , case when $val_date - effective_start_date - 1 >=\n",
    "            case when dt.category = 'Popcorn' and year(effective_start_date) < 2022 then 31 else 90 end\n",
    "        then 1 else 0 end as finished_window_flag\n",
    "    from dates dt\n",
    "    left join hv\n",
    "    on dt.title_id = hv.title_id\n",
    "    and dt.season_number = hv.season_number\n",
    "    and dt.request_date = hv.request_date\n",
    "    and dt.content_category = hv.content_category\n",
    "    and dt.category = hv.category\n",
    "    and dt.tier = hv.tier\n",
    "    left join fv\n",
    "    on dt.title_id = fv.title_id\n",
    "    and dt.season_number = fv.season_number\n",
    "    and dt.request_date = fv.request_date\n",
    "    and dt.content_category = fv.content_category\n",
    "    and dt.category = fv.category\n",
    "    and dt.tier = fv.tier\n",
    "    where 1 = 1\n",
    "    --and dt.title_name like 'In Treatment'\n",
    "    order by title_id, title_name, season_number, category, request_date\n",
    ")\n",
    ";\n",
    "\n",
    "create or replace table max_dev.workspace.psi_median_decay as (\n",
    "with title_totals as (\n",
    "select\n",
    "      title_id\n",
    "    , title_name\n",
    "    , season_number\n",
    "    , content_category\n",
    "    , category\n",
    "    , tier\n",
    "    , finished_window_flag\n",
    "    , sum(first_views) as total_first_views\n",
    "    , sum(hours_viewed) as total_hours_viewed\n",
    "from max_dev.workspace.psi_past_base_temp\n",
    "--where finished_window_flag = 1\n",
    "group by 1,2,3,4,5,6,7\n",
    ")\n",
    ", enriched_base as (\n",
    "select\n",
    "    base.*\n",
    "    , div0(first_views,total_first_views) as first_views_pct\n",
    "    , div0(hours_viewed,total_hours_viewed) as hours_viewed_pct\n",
    "from max_dev.workspace.psi_past_base_temp base\n",
    "left join title_totals tt\n",
    "on base.title_id = tt.title_id\n",
    "and base.season_number = tt.season_number\n",
    "and base.content_category = tt.content_category\n",
    "and base.category = tt.category\n",
    "and base.tier = tt.tier\n",
    "and tt.finished_window_flag = 1\n",
    "where 1 = 1\n",
    "and total_first_views >= 0\n",
    "or base.finished_window_flag = 0\n",
    ")\n",
    ", median_decay_pre as (\n",
    "select\n",
    "      category\n",
    "    , days_since_premiere\n",
    "    , median(hours_viewed_pct) as med_hours_viewed_pct\n",
    "    , median(first_views_pct) as med_first_views_pct\n",
    "from enriched_base\n",
    "where finished_window_flag = 1\n",
    "group by 1,2\n",
    "order by 1,2\n",
    ")\n",
    ", median_decay_modifier as (\n",
    "select\n",
    "      category\n",
    "    , sum(med_hours_viewed_pct) as med_hv_mod\n",
    "    , sum(med_first_views_pct) as med_fv_mod\n",
    "from median_decay_pre\n",
    "group by 1\n",
    ")\n",
    "--, median_decay as (\n",
    "select\n",
    "      a.category\n",
    "    , days_since_premiere\n",
    "    , med_hours_viewed_pct/med_hv_mod as med_hours_viewed_pct\n",
    "    , med_first_views_pct/med_fv_mod as med_first_views_pct\n",
    "from median_decay_pre a\n",
    "join median_decay_modifier b\n",
    "on a.category = b.category\n",
    ")\n",
    ";\n",
    "\n",
    "create or replace temporary table max_dev.workspace.psi_past_current_daily_viewership as (\n",
    "with current_running_assets as (\n",
    "select\n",
    "      title_id\n",
    "    , title_name\n",
    "    , season_number\n",
    "    , content_category\n",
    "    , category\n",
    "    , tier\n",
    "    , effective_start_date\n",
    "    , max(days_since_premiere) days_so_far\n",
    "    , sum(hours_viewed) as hv_so_far\n",
    "    , sum(first_views) as fv_so_far\n",
    "from max_dev.workspace.psi_past_base_temp\n",
    "where 1 = 1\n",
    "and request_date < dateadd('days',-1,$val_date)\n",
    "and effective_start_date < dateadd('days',-4,$val_date)\n",
    "and finished_window_flag = 0\n",
    "group by 1,2,3,4,5,6,7\n",
    ")\n",
    ", current_running_assets_enriched as (\n",
    "select\n",
    "      title_id\n",
    "    , title_name\n",
    "    , season_number\n",
    "    , content_category\n",
    "    , a.category\n",
    "    , a.tier\n",
    "    , effective_start_date\n",
    "    , days_so_far\n",
    "    , hv_so_far\n",
    "    , sum(med_hours_viewed_pct) hv_pct_so_far\n",
    "    , fv_so_far\n",
    "    , sum(med_first_views_pct) fv_pct_so_far\n",
    "from current_running_assets a\n",
    "join max_dev.workspace.psi_median_decay b\n",
    "on case when a.category = 'Popcorn' and year(effective_start_date) >= 2022 then 'Scripted Features'\n",
    "    else a. category end = b.category\n",
    "and days_since_premiere <= days_so_far\n",
    "group by 1,2,3,4,5,6,7,8,9,11\n",
    ")\n",
    ", current_running_assets_predicted_totals as (\n",
    "select\n",
    "      title_id\n",
    "    , title_name\n",
    "    , season_number\n",
    "    , content_category\n",
    "    , category\n",
    "    , tier\n",
    "    , effective_start_date\n",
    "    , hv_so_far/hv_pct_so_far as predicted_total_hours_viewed\n",
    "    , fv_so_far/fv_pct_so_far as predicted_total_first_views\n",
    "from current_running_assets_enriched\n",
    ")\n",
    "--, past_current_daily_predictions as (\n",
    "select\n",
    "      a.*\n",
    "    , case when request_date < dateadd('days',-1, $val_date) then first_views\n",
    "    else round(b.med_first_views_pct * c.predicted_total_first_views,0) end as predicted_first_views\n",
    "    , case when request_date < dateadd('days',-1, $val_date) then hours_viewed\n",
    "    else round(b.med_hours_viewed_pct * c.predicted_total_hours_viewed,3) end as predicted_hours_viewed\n",
    "from max_dev.workspace.psi_past_base_temp a\n",
    "left join max_dev.workspace.psi_median_decay b\n",
    "on case when a.category = 'Popcorn' and year(effective_start_date) >= 2022 then 'Scripted Features'\n",
    "    else a. category end = b.category\n",
    "and a.days_since_premiere = b.days_since_premiere\n",
    "left join current_running_assets_predicted_totals c\n",
    "on a.title_id = c.title_id\n",
    "and a.season_number = c.season_number\n",
    "and a.content_category = c.content_category\n",
    "and a.category = c.category\n",
    "and a.tier =  c.tier\n",
    "--where a.title_name like '%Snyder%'\n",
    ");\n",
    "\n",
    "create or replace table max_dev.workspace.psi_past_current_inferred_decay_values as (\n",
    "with title_totals as (\n",
    "select\n",
    "      title_id\n",
    "    , title_name\n",
    "    , season_number\n",
    "    , content_category\n",
    "    , category\n",
    "    , tier\n",
    "    , effective_start_date\n",
    "    , sum(predicted_hours_viewed) as total_hours_viewed\n",
    "    , sum(predicted_first_views) as total_first_views\n",
    "from max_dev.workspace.psi_past_current_daily_viewership\n",
    "--where tier = 1 and category = 'Scripted Drama Series'\n",
    "where effective_start_date < dateadd('days',-4,$val_date)\n",
    "group by 1,2,3,4,5,6,7\n",
    ")\n",
    ", recency_rank as (\n",
    "select *\n",
    "    , dense_rank() over (partition by category, tier order by effective_start_date) as recency_rank\n",
    "    , total_first_views*(dense_rank() over (partition by category, tier order by effective_start_date)) as weighted_first_views\n",
    "    , total_hours_viewed*(dense_rank() over (partition by category, tier order by effective_start_date)) as weighted_hours_viewed\n",
    "from title_totals\n",
    "order by category, tier, effective_start_date\n",
    ")\n",
    ", tier_x_catg_weighted_avgs as (\n",
    "select\n",
    "      category\n",
    "    , round(tier,0)::varchar as tier\n",
    "    , sum(weighted_hours_viewed)/sum(recency_rank) as avg_hours_viewed\n",
    "    , sum(weighted_first_views)/sum(recency_rank) as avg_first_views\n",
    "from recency_rank\n",
    "group by 1,2\n",
    "order by 1,2\n",
    ")\n",
    "--, median_decay_values as (\n",
    "select\n",
    "      a.category\n",
    "    , tier\n",
    "    , days_since_premiere\n",
    "    , round(avg_hours_viewed * med_hours_viewed_pct,4) as predicted_hours_viewed\n",
    "    , round(avg_first_views * med_first_views_pct,0) as predicted_first_views\n",
    "from max_dev.workspace.psi_median_decay a\n",
    "join (\n",
    "    select * from tier_x_catg_weighted_avgs\n",
    "    union\n",
    "    select\n",
    "          category\n",
    "        , '0' as tier\n",
    "        , avg_hours_viewed*7\n",
    "        , avg_first_views*7\n",
    "    from tier_x_catg_weighted_avgs\n",
    "    where tier = '1'\n",
    ") b\n",
    "on a.category = b.category\n",
    "order by 1,2,3\n",
    ")\n",
    ";\n",
    "\n",
    "\n",
    "select\n",
    "      null as title_id\n",
    "    , a.title as title_name\n",
    "    , a.season as season_number\n",
    "    , null as content_category\n",
    "    , source as content_source\n",
    "    , null as program_type\n",
    "    , initcap(a.category) as category\n",
    "    , a.tier\n",
    "    --, a.season_premiere\n",
    "    , a.premiere_date\n",
    "    , a.seq_date\n",
    "    , num_premiering_titles\n",
    "    , num_episodes_released\n",
    "    , num_hours_released\n",
    "    , 0 as first_views\n",
    "    , 0 as hours_viewed\n",
    "    , seq_date::date - a.premiere_date as days_since_premiere\n",
    "    , $val_date - 1 - a.premiere_date as days_on_platform\n",
    "    , 0 as finished_window_flag\n",
    "    , b.predicted_first_views\n",
    "    , b.predicted_hours_viewed\n",
    "    , schedule_label\n",
    "from max_prod.content_analytics.daily_future_programming_schedule a\n",
    "left join max_dev.workspace.psi_past_current_inferred_decay_values b\n",
    "on case when initcap(a.category) = 'Popcorn' and year(a.premiere_date) >= 2022 then 'Scripted Features'\n",
    "    else initcap(a. category) end = initcap(b.category)\n",
    "and seq_date - a.premiere_date = b.days_since_premiere\n",
    "and a.tier::varchar = b.tier::varchar\n",
    "where 1 = 1\n",
    "and first_window_flag = 1\n",
    "and finished_window_flag = 0\n",
    "and premiere_date >= dateadd('days',-4, $val_date)\n",
    "and concat(title,season) not in (\n",
    "    select distinct concat(psi_title,a.season_number)\n",
    "    from max_dev.workspace.psi_past_current_daily_viewership a\n",
    "    join max_prod.content_analytics.psi_past_title_metadata b\n",
    "    on initcap(a.title_name) = initcap(b.viewership_title)\n",
    "    and coalesce(a.season_number,0) = coalesce(b.viewership_season_number,0)\n",
    "    where premiere_ind = 1\n",
    "    and a.effective_start_date < dateadd('days',-4, $val_date)\n",
    ")\n",
    ";\n",
    "\n",
    "'''\n",
    "\n",
    "cursor_list = ctx.execute_string(\n",
    "    querystr\n",
    "    )\n",
    "df = pd.DataFrame.from_records(cursor_list[-1].fetchall(), columns=[x[0] for x in cursor_list[-1].description])\n",
    "df.columns= df.columns.str.lower()\n",
    "print(df.head())\n",
    "df.to_csv('s3://datascience-hbo-users/users/tjung/psi/fv_pred_decay_new_210901.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
